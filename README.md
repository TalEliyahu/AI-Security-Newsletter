# AI Security Digest â€“ June 2025

A digest of AI security research, insights, reports, upcoming events, and tools & resources. Follow the [AI Security community](https://linktr.ee/AISECHUB) on [Twitter](https://twitter.com) and [LinkedIn group](https://linkedin.com) for additional updates.

Sponsored by [CyberBiz](https://cyber-biz.com/) and [InnovGuard.com](https://innovguard.com) â€“ Technology Risk & Cybersecurity Advisory, Innovate and Invest with Confidence, Lead with Assurance.

## ğŸ” Insights

ğŸ“Œ Mapping: MAESTRO Threatsâ€Šâ€”â€ŠMITRE D3FEND Techniquesâ€Šâ€”â€ŠThis website presents an interactive exploration of the intersection between two pivotal cybersecurity frameworks: MAESTRO and MITRE D3FEND. It aims to provide cybersecurity professionals with actionable insights into securing Agentic AI systems by mapping identified threats to corresponding defensive techniques, by Edward Lee. https://edward-playground.github.io/maestro-d3fend-mapping/

ğŸ“Œ 10 Key Risks of Shadow AIâ€Šâ€”â€ŠA practical breakdown of Shadow AI: how unmanaged AI useâ€Šâ€”â€Šincluding tools, models, and featuresâ€Šâ€”â€Šcreates hidden risks across security, compliance, data, and governance. https://www.linkedin.com/pulse/10-key-risks-shadow-ai-tal-eliyahu-9aopc/

ğŸ“Œ How an AI Agent Vulnerability in LangSmith Could Lead to Stolen API Keys and Hijacked LLM Responses - by Sasi Levi and Gal Moyal, Noma Security - https://noma.security/blog/how-an-ai-agent-vulnerability-in-langsmith-could-lead-to-stolen-api-keys-and-hijacked-llm-responses/

ğŸ“Œ Explore the latest threats to Model Context Protocol (MCP)â€Šâ€”â€Šcovering issues from prompt injection to agent hijackingâ€Šâ€”â€Šin this digest collected by Adversa AI. https://adversa.ai/blog/mcp-security-digest-june-2025/

ğŸ“Œ GenAI Guardrails: Implementation & Best Practicesâ€Šâ€”â€Š Lasso outlines how organizations are designing and deploying guardrails for generative AIâ€Šâ€”â€Šincluding challenges, frameworks, and real-world examples. https://www.lasso.security/blog/genai-guardrails

ğŸ“Œ Trend Microâ€™s â€œUnveiling AI Agent Vulnerabilitiesâ€ 4-part series explores key security threats in agentic AI systemsâ€Šâ€”â€Šincluding [Part I: Introduction](https://www.trendmicro.com/vinfo/us/security/news/threat-landscape/unveiling-ai-agent-vulnerabilities-part-i-introduction-to-ai-agent-vulnerabilities), [Part II: Code Execution](https://www.trendmicro.com/vinfo/us/security/news/cybercrime-and-digital-threats/unveiling-ai-agent-vulnerabilities-code-execution), [Part III: Data Exfiltration](https://www.trendmicro.com/vinfo/us/security/news/threat-landscape/unveiling-ai-agent-vulnerabilities-part-iii-data-exfiltration), and [Part IV: Database Access](https://www.trendmicro.com/vinfo/us/security/news/vulnerabilities-and-exploits/unveiling-ai-agent-vulnerabilities-part-iv-database-access-vulnerabilities).

ğŸ“Œ Malicious AI Models Undermine Software Supply-Chain Securityâ€Šâ€”â€Šhttps://cacm.acm.org/research/malicious-ai-models-undermine-software-supply-chain-security/

ğŸ“Œ Leaking Secrets in the Age of AIâ€Šâ€”â€Š Shay Berkovich and Rami McCarthy scanned public repos and found widespread AI-related secret leaksâ€Šâ€”â€Šdriven by notebooks, hardcoded configs, and gaps in todayâ€™s secret scanning tools. https://www.wiz.io/blog/leaking-ai-secrets-in-public-code

ğŸ“Œ What is AI Assets Sprawl? Causes, Risks, and Control Strategiesâ€Šâ€”â€Š Dor Sarig from Pillar Security explores how unmanaged AI models, prompts, and tools accumulate across enterprisesâ€Šâ€”â€Šcreating security, compliance, and visibility challenges without proper controls. https://www.pillar.security/blog/what-is-ai-assets-sprawl-causes-risks-and-control-strategies   

ğŸ“Œ Is your AI safe? Threat analysis of MCPâ€Šâ€”â€Š Nil Ashkenazi outlines how Model Context Protocol (MCP) introduces risks like tool misuse, prompt-based exfiltration, and unsafe server chaining. Focus is on real-world attack paths and how insecure integrations can be exploited. https://www.cyberark.com/resources/threat-research-blog/is-your-ai-safe-threat-analysis-of-mcp-model-context-protocol

ğŸ“Œ A New Identity Framework for AI Agentsâ€Š by Omar Santos â€”â€ŠWe are all experiencing the rapid proliferation of autonomous AI agents and Multi-Agent Systems (MAS). These are no longer AI chatbots and assistants; they are increasingly self-directed entities capable of making decisions, performing actions, and interacting with critical systems at unprecedented scales. We need to perform fundamental re-evaluations of how identities are managed and access is controlled for these AI agents. https://community.cisco.com/t5/security-blogs/a-new-identity-framework-for-ai-agents/ba-p/5294337

ğŸ“Œ Hunting Deserialization Vulnerabilities With Claudeâ€Šâ€”â€Š TrustedSec exploring how to find zero-days in .NET assemblies using Model Context Protocol (MCP). https://trustedsec.com/blog/hunting-deserialization-vulnerabilities-with-claude

ğŸ“Œ Uncovering Nytheon AI â€” Vitaly Simonovich ğŸ‡®ğŸ‡± from Cato Networks, analyzes Nytheon AI, a Tor-based GenAI platform built from jailbroken open-source models (Llama 3.2, Gemma, Qwen2), offering code generation, multilingual chat, image parsing, and API accessâ€Šâ€”â€Šwrapped in a modern SaaS-style interface. https://www.catonetworks.com/blog/cato-ctrl-nytheon-ai-a-new-platform-of-uncensored-llms/

ğŸ“Œ Touchpoints Between AI and Non-Human Identitiesâ€Šâ€”â€Š Tal Skverer from Astrix Security and Ophir Oren ğŸ‡®ğŸ‡± from Bayer examine how AI agents rely on non-human identities (NHIs)â€Šâ€”â€ŠAPI keys, service accounts, OAuth appsâ€Šâ€”â€Što operate across platforms. Unlike traditional automation, these agents request dynamic access, mimic users, and often require multiple NHIs per task, creating complex, opaque identity chains. https://astrix.security/learn/blog/astrix-research-presents-touchpoints-between-ai-and-non-human-identities/

ğŸ“Œ Breaking down â€˜EchoLeakâ€™, Vulnerability Enabling Data Exfiltration from Microsoft 365 Copilotâ€Šâ€”â€Š Itay Ravia and other members of Aim Security identified a vulnerability in Microsoft 365 Copilot where specially crafted emails can trigger data leakage through prompt injection and markdown/CSP bypasses. The issue stems from how Copilot processes untrusted input, potentially exposing internal content. https://www.aim.security/lp/aim-labs-echoleak-blogpost

ğŸ“Œ Remote Prompt Injection in GitLab Duo Leads to Source Code Theftâ€Šâ€”â€Š Legit Securityâ€™s Omer Mayraz demonstrates how a single hidden comment could trigger GitLab Duo (Claude-powered) to leak private source code, suggest malicious packages, and exfiltrate zero-days. The exploit chain combines prompt injection, invisible text, markdown-to-HTML rendering abuse, and access to sensitive contentâ€Šâ€”â€Šshowcasing the real-world risks of deeply integrated AI agents in developer workflows. https://www.legitsecurity.com/blog/remote-prompt-injection-in-gitlab-duo

ğŸ“Œ ISO/IEC 42005:2025 has been formally published. ISO 42005 provides guidance for organizations conducting AI system impact assessments. Establishing a process and performing an AI system impact assessment is integral for organizations looking to pursue ISO 42001 certification. More importantly, the AI impact assessment allows organizations to identify high risk AI systems and determine any potential impact to individuals, groups, or societies as it relates to fairness, safety, and transparency. https://www.ethos-ai.org/p/ai-impact-checklist or https://www.linkedin.com/posts/noureddine-kanzari-a852a6181_iso-42005-the-standard-of-the-future-activity-7334498579710943233-ts6S

ğŸ“Œ Checklist for LLM Compliance in Governmentâ€Šâ€”â€ŠDeploying AI in government? Compliance isnâ€™t optional. Missteps can lead to fines reaching $38.5M under global regulations like the EU AI Actâ€Šâ€”â€Šor worse, erode public trust. This checklist ensures your government agency avoids pitfalls and meets ethical standards while deploying large language models (LLMs). https://www.newline.co/@zaoyang/checklist-for-llm-compliance-in-government--1bf1bfd0

ğŸ“Œ How I used o3 to find CVE-2025â€“37899, a remote zeroday vulnerability in the Linux kernelâ€™s SMB implementation by Sean Heelan. https://sean.heelan.io/2025/05/22/how-i-used-o3-to-find-cve-2025-37899-a-remote-zeroday-vulnerability-in-the-linux-kernels-smb-implementation/

