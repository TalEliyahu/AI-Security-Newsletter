# Adversarial AI Digest – 20 May, 2025
A digest of AI security research, insights, reports, upcoming events, and tools & resources.  
Follow AI Security community on Twitter and LinkedIn group for additional updates.  

**Sponsored by InnovGuard.com - Technology Risk & Cybersecurity Advisory - Innovate and Invest with Confidence, Lead with Assurance.**

## 🔍 Insights
📌 [AI Agents vs. Agentic AI — Design Is Defense](https://medium.com/ai-security-hub/ai-agents-vs-agentic-ai-ecfc5d8f41b6) — How AI Agents and Agentic AI really differ — and why security needs to be part of the design, not an afterthought.

📌 [MITRE ATT&CK Adds Sub-Technique T1588.007: Adversaries Leveraging AI](https://attack.mitre.org/techniques/T1588/007/) — ATT&CK v17 introduces a new sub-technique to document how adversaries use LLMs for phishing, payload automation, reconnaissance, and social engineering.

📌 [Agentic AI Security: Key Threats, Attacks, and Defenses](https://adversa.ai/blog/agentic-ai-security/) - Agentic AI systems bring autonomy, memory, and tool use—introducing novel risks like memory injection, tool poisoning, and multi-agent deception. Alex Polyakov at Adversa AI explores why traditional GenAI defenses fall short and how red teaming, sandboxing, and permission controls are essential for securing next-gen autonomous agents.

📌 [AI-Powered Mystery Box Scams](https://infosecwriteups.com/ai-powered-mystery-box-scams-02e931065a19) — These scams have flooded social platforms, using AI-generated ads, fake influencers, chatbot support, deepfake visuals, and autogenerated reviews to scale deception.

📌 [Xanthorox AI](https://medium.com/ai-security-hub/xanthorox-ai-84c9d22d3d48) - Xanthorox AI is a self-hosted, multi-model AI platform emerging in cybercrime communities. Xanthorox is built from the ground up to operate entirely offline, avoiding dependence on commercial APIs or cloud infrastructure.

📌 [Nytheon AI](https://medium.com/ai-security-hub/nytheon-ai-1cb2cbc069ec) — A dark web GenAI tool with multi-language, real-time malware generation, phishing campaign orchestration, OCR, code writing, and cross-modal capabilities.

📌 [Palo Alto Networks Unit 42 on Synthetic Identity Creation](https://unit42.paloaltonetworks.com/north-korean-synthetic-identity-creation/) — North Korean IT workers are using real-time deepfakes to obtain remote jobs and infiltrate organizations.

📌 [How I Used AI to Create a Working Exploit for CVE-2025-32433 by Matthew Keeley](https://platformsecurity.com/blog/CVE-2025-32433-poc) — GPT-4 identified the vulnerability, compared the patch, and generated a working PoC.

📌 [Darcula — GenAI-Powered Phishing Kit](https://medium.com/ai-security-hub/darcula-genai-powered-phishing-kit-d5c22998c660) - The new version of Darcula, expands its phishing-as-a-service (PhaaS) platform with GenAI-powered phishing kit creation, multi-language templates, customizable forms, and no coding required.

📌 [AI Slop Is Polluting Bug Bounty Platforms](https://socket.dev/blog/ai-slop-polluting-bug-bounty-platforms) — Sarah Gooding explores how AI-generated fake vuln reports are wasting triage cycles and damaging trust.

📌 [Everything Wrong with MCP](https://blog.sshh.io/p/everything-wrong-with-mcp) — Shrivu Shankar details key flaws in the Model Context Protocol, including trust boundaries, cost control limitations, and prompt injection exposure.

📌 [How to Pitch at RSA Conference Innovation Sandbox, Black Hat Startup Spotlight, and GISEC GLOBAL Cyberstars](https://www.linkedin.com/pulse/how-win-cybersecurity-oscar-tal-eliyahu-aobec/) — Cybersecurity startup competitions are more than just pitch stages — they’re credibility engines. This article breaks down what judges actually look for, how AI security is reshaping the field, and why early-stage founders should treat these competitions like investor-level opportunities.
