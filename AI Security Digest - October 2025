# AI Security Digest - October 2025

A digest of AI security research, insights, reports, upcoming events, and tools & resources. Follow the [AI Security community](https://x.com/AISecHub) and our [LinkedIn group](https://www.linkedin.com/groups/14545517/) for additional updates. Also check out our project, [Awesome AI Security](https://github.com/TalEliyahu/Awesome-AI-Security).

Sponsored by [InnovGuard.com](https://innovguard.com) - Technology Risk & Cybersecurity Advisory - Innovate and Invest with Confidence, Lead with Assurance.

# ğŸ” Insights

ğŸ“Œ [Prompt injection to RCE in AI agents](https://blog.trailofbits.com/2025/10/22/prompt-injection-to-rce-in-ai-agents/)  
Design antipatterns enable argument injection to reach command execution across multiple agent platforms under coordinated disclosure.

ğŸ“Œ [Meet Aardvark - OpenAI's GPT-5 Powered Autonomous Security Agent](https://kenhuangus.substack.com/p/meet-aardvark-openais-gpt-5-powered)  
GPT-5 powered agent monitors codebases, validates exploits, and generates patches - currently in private beta.

ğŸ“Œ [Analyzing The Security Risks of OpenAI's AgentKit](https://labs.zenity.io/p/analyzing-the-security-risks-of-openai-s-agentkit)  
Security review of AgentKit - attack surface, pitfalls, and mitigations for agentic workflows in OpenAIâ€™s platform.

ğŸ“Œ [AI Security Startups Watchlist - Top 30 2025](https://www.linkedin.com/pulse/ai-security-startups-watchlist-top-30-2025-tal-eliyahu-ozqwc/)  
Neutral, unsponsored list tracking startups securing models, agents, data paths, and identities.

ğŸ“Œ [OpenAI's new browser Atlas falls for AI-targeted cloaking attack](https://splx.ai/blog/ai-targeted-cloaking-openai-atlas)  
Agent-aware cloaking serves different realities to humans and AI browsers like Atlas, ChatGPT, and Perplexity.

ğŸ“Œ [Introducing CodeMender - an AI agent for code security](https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/)  
Early results on an AI agent improving code security by finding and fixing vulnerabilities at scale.

ğŸ“Œ [Vibecoding and the illusion of security](https://baldur.dk/blog/vibecoding-and-the-illusion-of-security.html)  
Attempt to vibecode a secure 2FA app followed by manual review that exposes missed vulnerabilities.

ğŸ“Œ [Top 6 MCP Vulnerabilities and How to Fix Them](https://www.descope.com/blog/post/mcp-vulnerabilities)  
Six MCP risks - tool poisoning, neighborjacking, cross server shadowing, spoofing and token theft, lethal trifecta, rug pull updates - with defenses.

ğŸ“Œ [Building Secured Agents - Soft Guardrails, Hard Boundaries, and the Layers Between](https://idanhabler.medium.com/building-safer-agents-soft-guardrails-hard-boundaries-and-the-layers-between-14205d709b93)  
Agents that think, plan, and act require boundaries and control - trust and prompts are not enough.

ğŸ“Œ [CoPhish - Using Microsoft Copilot Studio as a wrapper for OAuth phishing](https://securitylabs.datadoghq.com/articles/cophish-using-microsoft-copilot-studio-as-a-wrapper/)  
Consent-policy changes help but exploitable OAuth scenarios remain for internal apps and privileged admins.

ğŸ“Œ [Prompt Hijacking Attack - How Session Hijacking Affects MCP Ecosystems](https://jfrog.com/blog/mcp-prompt-hijacking-vulnerability/)  
Conditions and impact of prompt hijacking with CVE-2025-6515 as a case study.

ğŸ“Œ ["Prompt Inception" - When AI Becomes the Single Source of Truth](https://guard.io/labs/prompt-inception-when-ai-becomes-the-single-source-of-truth-whose-truth-will-it-be)  
Invisible Unicode and image OCR inject instructions into agent prompts - gaps in preprocessing and sanitization.

ğŸ“Œ [Unseeable prompt injections in screenshots](https://brave.com/blog/unseeable-prompt-injections/)  
Indirect prompt injection via screenshots is systemic across AI browsers beyond the original Comet disclosure.

ğŸ“Œ [From Assistant to Adversary - Exploiting Agentic AI Developer Tools](https://developer.nvidia.com/blog/from-assistant-to-adversary-exploiting-agentic-ai-developer-tools/)  
Watering-hole attacks plus assistive alignment and autonomy can lead to RCE on developer machines.

ğŸ“Œ [Metanarrative Prompt Injection](https://josephthacker.com/hacking/2025/10/20/metanarrative-prompt-injection.html)  
Technique directly addresses the top-level AI or a specific processing step to steer behavior.

ğŸ“Œ [Microsoft 365 Copilot - Arbitrary Data Exfiltration Via Mermaid Diagrams](https://adamlogue.com/microsoft-365-copilot-arbitrary-data-exfiltration-via-mermaid-diagrams-fixed/)  
Indirect prompt injection turns a Mermaid diagram into a clickpath that exfiltrates hex-encoded tenant data.

ğŸ“Œ [The Growing Challenge of AI Agent and NHI Management](https://www.darkreading.com/cybersecurity-operations/growing-challenge-ai-agent-nhi-management)  
Agents and machine identities already outnumber humans - stressing identity, policy, and governance.

ğŸ“Œ [Hugging Face and VirusTotal collaborate to strengthen AI security](https://huggingface.co/blog/virustotal)  
Continuous VirusTotal scanning across 2.2M plus public model and dataset repos on the Hub.

ğŸ“Œ [OAuth for MCP - Emerging Enterprise Patterns for Agent Authorization](https://blog.gitguardian.com/oauth-for-mcp-emerging-enterprise-patterns-for-agent-authorization/)  
Sequence-level risks in agent interactions require patterns that go beyond request-level OAuth checks.

ğŸ“Œ [Same Model, Different Hat - Bypassing OpenAI Guardrails](https://hiddenlayer.com/innovation-hub/same-model-different-hat/)  
Using the same model family to both generate and judge safety can couple failure modes and be bypassed.

ğŸ“Œ [LOLMIL - Living Off the Land Models and Inference Libraries](https://dreadnode.io/blog/lolmil-living-off-the-land-models-and-inference-libraries)  
Living-off-the-land patterns for LLM era malware - C2-less concepts inspired by classic cyberpunk visions.

ğŸ“Œ [The security paradox of local LLMs](https://quesma.com/blog/local-llms-security-paradox/)  
Local models comply far more with malicious prompts than frontier models - higher jailbreak success rates.

ğŸ“Œ [How a fake AI recruiter delivers five staged malware disguised as a dream job](https://medium.com/deriv-tech/how-a-fake-ai-recruiter-delivers-five-staged-malware-disguised-as-a-dream-job-64cc68fec263)  
Multi-stage malware via social engineering and AI-native distribution channels.

ğŸ“Œ [The Highs and Lows of Vibe Coding](https://snyk.io/articles/the-highs-and-lows-of-vibe-coding/)  
Democratization and speed vs catastrophic vulnerabilities and maintenance debt in AI-generated code.

ğŸ“Œ [State of MCP Server Security 2025 - 5,200 Servers, Credential Risks, and an Open-Source Fix](https://astrix.security/learn/blog/state-of-mcp-server-security-2025/)  
Large-scale scan of open-source MCP servers shows widespread credential risks and misconfigurations.

ğŸ“Œ [LLM Poisoning 1/3 - Reading the Transformer's Thoughts](https://www.synacktiv.com/en/publications/llm-poisoning-13-reading-the-transformers-thoughts)  
Tiny weight edits implant stealth backdoors that fire on triggers - methodology to detect internal concepts.

ğŸ“Œ [From Path Traversal to Supply Chain Compromise - Breaking MCP Server Hosting](https://blog.gitguardian.com/breaking-mcp-server-hosting/)  
Smithery path traversal exposed thousands of API keys and more than 3,000 MCP servers.

ğŸ“Œ [Interpreting Jailbreaks and Prompt Injections with Attribution Graphs](https://labs.zenity.io/p/interpreting-jailbreaks-and-prompt-injections-with-attribution-graphs)  
Attribution graphs to map and reason about jailbreak chains and injection paths.

# ğŸ§° Tools & Resources

ğŸ§° **[mcp-scanner](https://github.com/cisco-ai-defense/mcp-scanner)** - MCP security scanner to find exposed or weak MCP servers. â­ï¸537  
ğŸ§° **[deep-eye](https://github.com/zakirkun/deep-eye)** - AI-driven vulnerability scanner and pentest assistant with multi-LLM support. â­ï¸408  
ğŸ§° **[vibe-check-mcp-server](https://github.com/PV-Bhat/vibe-check-mcp-server)** - MCP server to sanity-check agent actions before tool use. â­ï¸299  
ğŸ§° **[rules](https://github.com/project-codeguard/rules)** - Model-agnostic AI security ruleset for policy enforcement and unsafe tool detection. â­ï¸277  
ğŸ§° **[AI-VAPT](https://github.com/vikramrajkumarmajji/AI-VAPT)** - Autonomous AI-powered VAPT framework. â­ï¸66  
ğŸ§° **[leash](https://github.com/strongdm/leash)** - Control plane to leash and authorize AI agents within boundaries. â­ï¸56  
ğŸ§° **[hacktheweb](https://github.com/yashab-cyber/hacktheweb)** - AI-powered web app pentester with adaptive scans and reports. â­ï¸15  
ğŸ§° **[ai-and-ml-security-minicourse](https://github.com/kjam/ai-and-ml-security-minicourse)** - Hands-on labs on prompt bypass and guardrail evasion. â­ï¸14  
ğŸ§° **[BugPilot-Ai](https://github.com/letchupkt/BugPilot-Ai)** - AI desktop assistant orchestrating real security tools for bounty and pentest workflows. â­ï¸9  
ğŸ§° **[openvscan](https://github.com/Buddhsen-tripathi/openvscan)** - AI-assisted open-source vulnerability scanner for web assets. â­ï¸8  
ğŸ§° **[AI_SOC](https://github.com/zhadyz/AI_SOC)** - AI-augmented SOC stack for alert triage and investigations. â­ï¸4  
ğŸ§° **[aracne](https://github.com/stratosphereips/aracne)** - Autonomous agent for offensive and defensive SSH operations. â­ï¸3  
ğŸ§° **[adversarial-vision](https://github.com/NotSooShariff/adversarial-vision)** - Playground to craft adversarial inputs for vision plus LLM systems. â­ï¸1  
ğŸ§° **[prompt-security-standard](https://github.com/alvinveroy/prompt-security-standard)** - YAML-style standard to document and test GenAI and prompt security controls. â­ï¸0  
ğŸ§° **[soc-cert-guardian-extension](https://github.com/joupify/soc-cert-guardian-extension)** - Chrome extension with AI-assisted checks and CVE intel for SOC and CERT workflows. â­ï¸0  
ğŸ§° **[Aardvark - OpenAI's agentic security researcher](https://openai.com/index/introducing-aardvark/)** - GPT-5 powered agent that scans code, validates exploitability, and proposes patches.

# ğŸ“„ Reports

ğŸ“˜ [AI Incident Response Framework](https://www.linkedin.com/feed/update/urn:li:activity:7389438644538757120)  
Guidance for AI incident response updates classic playbooks for agentic systems - telemetry checklists, CACAO playbooks, architecture-aware steps.

ğŸ“˜ [AICM Auditing Guidelines](https://cloudsecurityalliance.org/artifacts/aicm-implementation-auditing-guidelines-frameworks)  
Structured auditing steps for organizations implementing AICM - role-specific accountability and traceability.

ğŸ“˜ [AICM Implementation Guidelines](https://cloudsecurityalliance.org/artifacts/aicm-implementation-auditing-guidelines-frameworks)  
Practical control guidance tailored to model providers, application providers, orchestrated services, customers, and cloud service providers.

ğŸ“˜ [Architecting secure enterprise AI agents with MCP](https://www.linkedin.com/feed/update/urn:li:activity:7382480880612724736)  
Agent development lifecycle to design, deploy, and manage enterprise agents safely.

ğŸ“˜ [Disrupting malicious uses of AI](https://www.linkedin.com/feed/update/urn:li:activity:7382084607397105665)  
Q3 case studies on abusive accounts, influence ops, scams, and cyber misuse - focus on detection and enforcement.

ğŸ“˜ [Agentic AI Runtime Security](https://www.linkedin.com/feed/update/urn:li:activity:7381693201478492160)  
A2AS framework as a runtime security layer for agents and LLM apps - certified behavior, context integrity, and policy enforcement.

# ğŸ“… Upcoming Events

ğŸ“… SANS Fall Cyber Solutions Fest - AI Track - November 6, 2025 - Virtual - SANS Institute  
ğŸ“… FAIRCON25 - AI Risk Management for Cyber - November 4-5, 2025 - New York, NY, USA - FAIR Institute  
ğŸ“… DataSecAI Conference 2025 - Securing AI-Driven Data and Agents - November 12-14, 2025 - Dallas, TX, USA - Cyera  
ğŸ“… Artificial Intelligence to Enhance Cybersecurity 2025 - November 13, 2025 - Virtual - Digital Government Institute  
ğŸ“… [AI Security Summit 2025](https://www.securitysummit.ai/) - November 12-13, 2025 - London, UK  
ğŸ“… [NHI Global Summit - Tackling NHI in the World of Agentic AI](https://nhimg.org/nhi-global-summit-london) - November 13, 2025 - London, UK  
ğŸ“… International Conference on Artificial Intelligence and Cybersecurity (ICAIC 2025) - November 27-28, 2025 - Osaka, Japan - Scientific Research Conferences  
ğŸ“… ISACA Virtual Summit - AI Governance Strategies 2025 - December 3, 2025 - Virtual - ISACA  
ğŸ“… North Carolina AI and Cybersecurity Symposium 2025 - December 3-4, 2025 - Raleigh, NC, USA - Government Technology  
ğŸ“… AI Security Summit @ Black Hat - December 9, 2025 - ExCeL London, UK  
ğŸ“… [AI Hacking Village @ BSidesTLV](https://bsidestlv.com/) - December 11, 2025 - Tel Aviv University, Tel Aviv, Israel - BSidesTLV

# ğŸ“š Research

ğŸ“– [The Backbone Breaker Benchmark - Testing the Real Security of AI Agents](https://arxiv.org/pdf/2510.22620)  
ğŸ“– [Black-box Optimization of LLM Outputs by Asking for Directions](https://arxiv.org/pdf/2510.16794)  
ğŸ“– [Genesis - Evolving Attack Strategies for LLM Web Agent Red-Teaming](https://www.arxiv.org/abs/2510.18314)  
ğŸ“– [Exploiting Web Search Tools of AI Agents for Data Exfiltration](https://arxiv.org/abs/2510.09093)  
ğŸ“– [LLM Agents for Automated Web Vulnerability Reproduction - Are We There Yet](https://arxiv.org/abs/2510.14700)  
ğŸ“– [Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples](https://arxiv.org/pdf/2510.07192)  
ğŸ“– [Uncertainty-Aware, Risk-Adaptive Access Control for Agentic Systems using an LLM-Judged TBAC Model](https://arxiv.org/pdf/2510.11414)  
ğŸ“– [Fingerprinting LLMs via Prompt Injection](https://arxiv.org/pdf/2509.25448)  
ğŸ“– [PACEbench - A Framework for Evaluating Practical AI Cyber-Exploitation Capabilities](https://arxiv.org/pdf/2510.11688v1)

# ğŸ¥ Videos

â–¶ï¸ Hackers Are Using This AI Tool  
â–¶ï¸ Deepfake Image and Video Detection - Mike Raggo  
â–¶ï¸ Thinking Like a Hacker in the Age of AI - Richard Thieme  
â–¶ï¸ Securing Agentic AI Systems and Multi-Agent Workflows - Andra Lezza and Jeremiah Edwards at Sage  
â–¶ï¸ Winners of DARPA's AI Cyber Challenge - Andrew Carney and Jason Roos and Stephen Winchell at DARPA  
â–¶ï¸ Claude - Climbing a CTF Scoreboard Near You - Keane L. at Anthropic  
â–¶ï¸ Vibe Hacking Using AI for Automation in Offensive and Defensive Ops - Brian Almond at Almond Consulting  
â–¶ï¸ Exploiting Shadow Data from AI Models and Embeddings - Patrick Walsh at IronCore Labs  
â–¶ï¸ AppleStorm - Unmasking the Privacy Risks of Apple Intelligence - Yoav Magid at Lumia Security Inc.  
â–¶ï¸ Invoking Gemini Agents with a Google Calendar Invite - Ben Nassi, Or Yair, and Stav Cohen  
â–¶ï¸ LLM Identifies Info Stealer Vector & Extracts IoCs - Olivier Bilodeau and Estelle Ruellan at Flare  
â–¶ï¸ Designing and Participating in AI Bug Bounty Programs - Dane Sherrets and Shlomie Liberow at HackerOne  
â–¶ï¸ AI, EDR, and Hacking Things - Security Weekly panel  
â–¶ï¸ Hacking Context for Auto Root Cause and Attack Flow Discovery - Ezz T. at Microsoft  
â–¶ï¸ Orion - Fuzzing Workflow Automation - Max Bazalii and Marius Fleischer  
â–¶ï¸ Vibe School - Making Dumb Devices Smart with AI - Katie Paxton-Fear  
â–¶ï¸ Automating Compliance and Risk with Agentic AI as CISOs (R)Evolve - Trevor Horwitz at TrustNet  
â–¶ï¸ Bypassing Intent Destination Checks, LaunchAnyWhere Privilege Escalation - Qidan He  
â–¶ï¸ Prompt. Scan. Exploit - AI's Journey Through Zero-Days and a Thousand Bugs - Joel Noguera PallarÃ©s and Diego Jurado PallarÃ©s at XBOW  
â–¶ï¸ Unveiling the Perils of the TorchScript Engine in PyTorch - Ji'an Zhou and Lishuo Song  
â–¶ï¸ Loading Models, Launching Shells - Abusing AI File Formats for Code Execution - Cyrus Parzian  
â–¶ï¸ AI-Orchestrated Penetration - Adapting Attacks in Real Time - YI-TING SHEN at Array Networks  
â–¶ï¸ Decision Making in Adversarial Automation - Bobby K. and Michael O'Dell at ProCircular  
â–¶ï¸ How AI + Hardware Can Transform Point of Care Workflows - Tianqi Kevin L. and Chengming Zhang  
â–¶ï¸ Cloned Vishing - A Case Study - Katherine Rackliffe  
â–¶ï¸ AI Agents - Your New Security Team Members or Biggest Threat - Michael Ifeanyi  
â–¶ï¸ Learn to Hack AI by Hacking AI - Satu Korhonen  
â–¶ï¸ Let AI Autogenerate Neural ASR Rules for OT Attacks via NLP - Mars C. and Jr-Wei Huang at TXOne Networks and Trend Micro  
â–¶ï¸ AI-Augmentation - Transforming Security Operations - Fritz Pamesa  
â–¶ï¸ HoloConnect AI - From Space to Biohacking - Dr. Fernando de la PeÃ±a at Aexa Aerospace  
â–¶ï¸ Tinker, Tailor, LLM Spy - Investigate & Respond to Attacks on GenAI Chatbots - Allyn Stott  
â–¶ï¸ Hype vs. Hands-On - What GenAI Actually Brings to ID & Response - Marvin N.  
â–¶ï¸ Building a Zero Trust MCP Server Gateway - Policy, Isolation, and Observability for AI Tooling - Aakansha Puri and Navjot Singh  
â–¶ï¸ AI-Assisted Security Automation - Vlatko Kosturjak
